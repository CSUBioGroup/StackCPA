{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mol2graph as mg\n",
    "import shutil\n",
    "from rdkit import Chem\n",
    "from mol2vec.features import mol2alt_sentence, MolSentence\n",
    "from gensim.models import word2vec\n",
    "import json\n",
    "import pickle\n",
    "import math\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdb2seq(pdb_file):\n",
    "    letters = {'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C', 'GLU': 'E', 'GLN': 'Q', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I', 'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P', 'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V'}\n",
    "    prev = '-1'\n",
    "    res = []\n",
    "    with open(pdb_file) as input_file:\n",
    "        for line in input_file:\n",
    "            if len(line) < 1: continue\n",
    "            if line[0:6].strip() != 'ATOM': continue\n",
    "            if line[21:27].strip() != prev:\n",
    "                res.append(letters[line[17:20]])\n",
    "            prev = line[21:27].strip()\n",
    "    return ''.join(res)\n",
    "\n",
    "def pdb2mol(in_path,file,out_path):\n",
    "    pocket = \"obabel -ipdb {} -omol2 -O {}\".format(os.path.join(in_path,file+'_pocket.pdb'),os.path.join(out_path,file+'_pocket.mol2'))\n",
    "    os.system(pocket)\n",
    "    \n",
    "def sentence2vec(sentence, model, unseen=None):\n",
    "    keys = set(model.wv.key_to_index.keys())\n",
    "    if unseen:\n",
    "        unseen_vec = model.wv.word_vec(unseen)\n",
    "        res = sum([model.wv.word_vec(y) if y in set(sentence) & keys else unseen_vec for y in sentence])\n",
    "    else:\n",
    "        res = sum([model.wv.word_vec(y) for y in sentence if y in set(sentence) & keys])\n",
    "    return res\n",
    "\n",
    "def smi2vec(smi, model):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    sentence = MolSentence(mol2alt_sentence(mol, 1))\n",
    "    mol_vec = sentence2vec(sentence, model, unseen='UNK')\n",
    "    return mol_vec\n",
    "\n",
    "def get_amino_vecs(model):\n",
    "    amino_smi = {\n",
    "        'A': 'CC(N)C(=O)O',\n",
    "        'R': 'N=C(N)NCCCC(N)C(=O)O',\n",
    "        'N': 'NC(=O)CC(N)C(=O)O',\n",
    "        'D': 'NC(CC(=O)O)C(=O)O',\n",
    "        'C': 'NC(CS)C(=O)O',\n",
    "        'E': 'NC(CCC(=O)O)C(=O)O',\n",
    "        'Q': 'NC(=O)CCC(N)C(=O)O',\n",
    "        'G': 'NCC(=O)O',\n",
    "        'H': 'NC(Cc1cnc[nH]1)C(=O)O',\n",
    "        'I': 'CCC(C)C(N)C(=O)O',\n",
    "        'L': 'CC(C)CC(N)C(=O)O',\n",
    "        'K': 'NCCCCC(N)C(=O)O',\n",
    "        'M': 'CSCCC(N)C(=O)O',\n",
    "        'F': 'NC(Cc1ccccc1)C(=O)O',\n",
    "        'P': 'O=C(O)C1CCCN1',\n",
    "        'S': 'NC(CO)C(=O)O',\n",
    "        'T': 'CC(O)C(N)C(=O)O',\n",
    "        'W': 'NC(Cc1c[nH]c2ccccc12)C(=O)O',\n",
    "        'Y': 'NC(Cc1ccc(O)cc1)C(=O)O',\n",
    "        'V': 'CC(C)C(N)C(=O)O'\n",
    "    }\n",
    "    amino_vec = {}\n",
    "    for amino in amino_smi:\n",
    "        amino_vec[amino] = smi2vec(amino_smi[amino], model)\n",
    "    return pd.DataFrame(amino_vec).T\n",
    "\n",
    "def seq2vec(seq, amino_vecs):\n",
    "    vecs = np.array(amino_vecs.loc[list(seq)])\n",
    "    return np.mean(vecs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_data(fpath,x):\n",
    "    ligands = json.load(open(fpath+\"ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "    proteins = json.load(open(fpath+\"proteins.txt\"), object_pairs_hook=OrderedDict)\n",
    "    Y = pickle.load(open(fpath + \"Y\",\"rb\"), encoding='latin1') ### TODO: read from raw\n",
    "    print(os.path.basename(fpath).lower())\n",
    "    \n",
    "    if x == 'davis':\n",
    "        Y = -(np.log10(Y/(math.pow(10,9))))\n",
    "        uni_data = pd.read_csv(fpath+'uniprot_gi_map_cleaned.csv')\n",
    "        uni_id = [str(row['uniprot']) for idx,row in uni_data.iterrows()]\n",
    "        pocket_failed = [str(row['pocket structure']) for idx,row in uni_data.iterrows()]\n",
    "    print(pocket_failed[0:10])\n",
    "    compounds,protein_seq,y = [],[],[]\n",
    "    pro_id,com_id = [],[]\n",
    "    for d_idx,(drug,smile) in enumerate(ligands.items()):\n",
    "        for p_idx,(protein,fasta) in enumerate(proteins.items()):\n",
    "            if math.isnan(Y[d_idx][p_idx]):\n",
    "                continue\n",
    "            if x == 'davis':\n",
    "                if uni_id[p_idx] == 'nan' or pocket_failed[p_idx] == 'FALSE':\n",
    "                    print(' null ')\n",
    "                    continue\n",
    "                pro_id.append(uni_id[p_idx])\n",
    "            else:\n",
    "                pro_id.append(protein)\n",
    "            \n",
    "            compounds.append(smile)\n",
    "            protein_seq.append(fasta)\n",
    "            y.append(Y[d_idx][p_idx])\n",
    "            com_id.append(drug)\n",
    "            \n",
    "            \n",
    "    if x == 'kiba':\n",
    "        y = [-i for i in y]\n",
    "        min_val = min(y)\n",
    "        y= [ i-min_val for i in y]\n",
    "        \n",
    "    return compounds,protein_seq,y,pro_id,com_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_pocket(dataset,deeppocket_path): \n",
    "    # err_id = set()  \n",
    "    # data_path = os.path.join(os.path.dirname(code_dir),dataset,'protein')\n",
    "    cnt = 0\n",
    "    code_dir = os.getcwd()\n",
    "    data_path = \"{}/{}/{}\".format(os.path.dirname(code_dir),'datasets',dataset)\n",
    "    pdb_list = os.listdir(os.path.join(data_path,'protein'))\n",
    "\n",
    "    if not os.path.exists(os.path.join(data_path,'pocket')):\n",
    "        os.mkdir(os.path.join(data_path,'pocket'))\n",
    "\n",
    "    os.chdir(deeppocket_path)\n",
    "    print(pdb_list)\n",
    "    for pdb in pdb_list:\n",
    "        uniprot_id = pdb.split('.')[0]\n",
    "        predict_command = \"python predict.py -p {} -c first_model_fold1_best_test_auc_85001.pth.tar -s seg0_best_test_IOU_91.pth.tar\".format(os.path.join(data_path,'protein',pdb))\n",
    "        i = os.system(predict_command)\n",
    "        print(i)\n",
    "        \n",
    "        if not os.path.exists(os.path.join(data_path,'protein',uniprot_id+'_nowat_pocket1.pdb')):\n",
    "            # err_id.add(uniprot_id)\n",
    "            print('pocket prediction faild in '+uniprot_id)\n",
    "            continue\n",
    "\n",
    "        os.rename(os.path.join(data_path,'protein',uniprot_id+'_nowat_pocket1.pdb'),os.path.join(data_path,'protein',uniprot_id+'_pocket.pdb'))\n",
    "        shutil.move(os.path.join(data_path,'protein',uniprot_id+'_pocket.pdb'),os.path.join(data_path,'pocket',uniprot_id+'_pocket.pdb'))\n",
    "        for i in ['_nowat_1.dx','_nowat.gninatypes','_nowat.pdb']:\n",
    "            file = \"{}/{}{}\".format(os.path.join(data_path,'protein'),uniprot_id,i)\n",
    "            os.remove(file)\n",
    "        nowat_dir=\"{}/{}{}\".format(os.path.join(data_path,'protein'),uniprot_id,'_nowat_out')\n",
    "        shutil.rmtree(nowat_dir)\n",
    "    \n",
    "    os.chdir(code_dir)\n",
    "    # return err_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets'\n",
    "datasets = ['PDBbind','kiba','davis']\n",
    "#select dataset default value: PDBbind\n",
    "x=datasets[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if x == 'PDBbind':\n",
    "    #extract pocket sequence \n",
    "    protein_seq = {}\n",
    "    pocket_seq = {}\n",
    "    for pdb_path in ['../datasets/PDBbind/refined-set', '../datasets/PDBbind/general-set']:\n",
    "        for name in os.listdir(pdb_path):\n",
    "            if name in ['index', 'readme']:\n",
    "                continue\n",
    "            protein_pdbfile = os.path.join(pdb_path, name, name + '_protein.pdb')\n",
    "            pocket_pdbfile = os.path.join(pdb_path, name, name + '_pocket.pdb')\n",
    "\n",
    "            protein_seq[name] = pdb2seq(protein_pdbfile)\n",
    "            pocket_seq[name] = pdb2seq(pocket_pdbfile)\n",
    "\n",
    "    data = pd.read_excel('../datasets/PDBbind/general_data.xlsx', skiprows=1)\n",
    "    data = data[~(data['Resolution']==\"NMR\")&~(data['Ligand Name'].str.contains(\"-mer\"))]\n",
    "    data['protein_seq'] = data['PDB code'].apply(lambda x : protein_seq[x])\n",
    "    data['pocket_seq'] = data['PDB code'].apply(lambda x : pocket_seq[x])\n",
    "    data = data[['PDB code', 'Canonical SMILES', 'protein_seq', 'pocket_seq', 'pKd pKi pIC50']]\n",
    "    data.rename(columns={'PDB code':'protein_id', 'Canonical SMILES':'compound', 'pKd pKi pIC50':'label'},inplace=True)\n",
    "    cols = list(data)\n",
    "    cols.insert(3,cols.pop(cols.index('compound')))\n",
    "\n",
    "else:\n",
    "    data = pd.DataFrame()\n",
    "    pocket_seq = {}\n",
    "    fpath = \"../datasets/{}/\".format(x)\n",
    "    \n",
    "    compounds,protein_seq,label,pdb_id,compound_id = extract_data(fpath,x)\n",
    "    #extract pocket\n",
    "    pocket_failed_set = extract_pocket(x,'./DeepPocket-main/')\n",
    "    print(pocket_failed_set)\n",
    "    \n",
    "    for name in os.listdir(os.path.join(fpath,'pocket')):\n",
    "        pocket_pdbfile = os.path.join(fpath, 'pocket', name)\n",
    "        pocket_seq[name] = pdb2seq(pocket_pdbfile)\n",
    "    \n",
    "    data['protein_id'] = pdb_id\n",
    "    data['compound_id'] = compound_id\n",
    "    data['protein_seq'] = protein_seq\n",
    "    data['pocket_seq'] = data['protein_id'].apply(lambda x : pocket_seq[x])\n",
    "    data['compound'] = compounds\n",
    "    data['label'] = label\n",
    "\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    code = row['protein_id']\n",
    "    if len(row['pocket_seq']) <= 30:\n",
    "        # short_set.add(code)\n",
    "        data.loc[idx,\"drop\"] = 'NA'\n",
    "        continue    \n",
    "# print(short_set)\n",
    "\n",
    "data = data.dropna()\n",
    "data.to_csv(\"{}/{}_input_data.csv\".format(path,x), index=None, sep=',')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare smi2vec vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load('mol2vec_300dim.pkl')\n",
    "amino_vecs_pd = get_amino_vecs(model)\n",
    "\n",
    "com_vec_pd = pd.DataFrame()\n",
    "com_vec_pd['vec'] = data['compound'].apply(lambda smi: smi2vec(smi, model))\n",
    "compound_vector = np.array([vec for vec in com_vec_pd['vec']])\n",
    "\n",
    "poc_vec_pd = pd.DataFrame()\n",
    "poc_vec_pd['vec'] = data['pocket_seq'].apply(lambda seq: seq2vec(seq, amino_vecs_pd))\n",
    "pocket_vector = np.array([vec for vec in poc_vec_pd['vec']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare graph2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../datasets/{}\".format(x)\n",
    "mol2_path = [\"{}/{}/{}-set\".format(dataset_path,'mol2','general'),\"{}/{}\".format(dataset_path,'pocket')]\n",
    "graph_path = \"{}/{}/{}\".format(dataset_path,'graph','pocket')\n",
    "graph_csv = \"{}/{}\".format(dataset_path,'pocket_graph.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    if x == 'PDBbind':\n",
    "        code = row['protein_id']\n",
    "        set = 'general'\n",
    "        if not os.path.exists(os.path.join(dataset_path,'general-set',code)):\n",
    "            set = 'refined' \n",
    "        in_path = \"{}/{}-set/{}\".format(dataset_path,set,code)\n",
    "        out_path = \"{}/{}/{}-set\".format(dataset_path,'mol2',set)\n",
    "        \n",
    "    else:\n",
    "        in_path = \"{}/{}\".format(dataset_path,'pocket') \n",
    "        out_path = \"{}/{}\".format(dataset_path,'mol2')\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    pdb2mol(in_path,code,out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.main(mol2_path[0],graph_path,\"aa\",False)\n",
    "g2v_command = \"python graph2vec.py --input-path {} --output-path {}\".format(graph_path,graph_csv)\n",
    "os.system(g2v_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_id = list(data['protein_id'])\n",
    "graph_data = pd.read_csv(graph_csv)\n",
    "graph_dict = {}\n",
    "\n",
    "if x == 'PDBbind':\n",
    "    graph_dict = {str(row['type']).split('_')[0]:row[1:] for idx,row in graph_data.iterrows()}\n",
    "    \n",
    "    graph_data_new = pd.DataFrame.from_dict(graph_dict,orient='index')\n",
    "    graph_data_new.reset_index(inplace=True)\n",
    "    graph_data_new.rename(columns={\"index\":\"type\"},inplace=True)\n",
    "else:\n",
    "    pdb_name = str(row['type']).split('_')[0]\n",
    "    graph_dict[pdb_name] = row[1:].to_list()    \n",
    "\n",
    "graph_vec = np.array([graph_dict[i].tolist() for i in pdb_id if i in graph_dict.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare protr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protr =\"Rscript protor.r {} {}\".format('~/StackCPA/datasets/PDBbind_input_data.csv','~/StackCPA/datasets/PDBbind_input_protr.csv')\n",
    "os.system(protr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "protr_vec = pd.read_csv('../datasets/{}_input_protr.csv'.format(x),skiprows=0,sep=',')\n",
    "protr_vec = protr_vec.iloc[:,1:]\n",
    "protr_vec = [row.tolist() for idx,row in protr_vec.iterrows()]\n",
    "protr_vector = np.array(protr_vec)\n",
    "protr_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poc = np.hstack((compound_vector, pocket_vector,graph_vec,protr_vector))\n",
    "y = np.array([x for x in data['label']])\n",
    "\n",
    "np.save('../data/X.npy', X_poc)\n",
    "np.save('../data/y.npy', y)\n",
    "\n",
    "X_poc.shape, y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccafa4d48fc79d2b8e17cdd6724d147a7e5dbdb2cd944b272ecdc3b4ad23042d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
